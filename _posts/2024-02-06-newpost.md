---
layout: post
title:  "Data Frame Manipulation and Visualization"
author: Tate Smith
description: Tutorial Blog Post   
image: "/assets/images/title.jpg"
---
## Introduction
Introducing the power of Pandas DataFrames! In this blog, we'll explore how these versatile tools revolutionize data analysis and manipulation. From structured tabular representation to seamless handling of diverse data types, Pandas offers a robust framework for efficient data processing. We'll delve into essential tasks like data cleaning, preprocessing, and manipulation, uncovering valuable insights and streamlining visualization.
## Content: 

* We first need to download data to our computer, so that we can work with it. Data sets can come in many different formats, such as a CSV (Comma-Seperated Values), JSON (JavaScript Object Notation), XML (eXtensible Markup Language), and so on. I will be working with a CSV for this tutorial. I like working with CSVs because they are simple, easy to understand and are compatible with a variety of platforms and software applications.

* Once we have downloaded our CSV open whatever code editor you are comfortable with. I am using Visual Studio code. Create a new Jupyter notebook. [Jupyter Notebooks](https://code.visualstudio.com/docs/datascience/jupyter-notebooks) are great because it is easy to test your code as you progress.Remember to set up your enviroment, the link provided will help you do so. 

* Now we read in our CSV into a Pandas Data Frame. After the read in, I usually take a look at the data frame, see how it is set up and familiarize myself with its contents. This is where the tabular data representation is useful.
  - `df = pd.read_csv('ufc-fighters-statistics.csv')`
  - `df.head()`


* After you familiarize yourself with your data frame, you can decide what you would like to further examine. 
  - Looking through my csv, I want to explore the relationship between fighter stance, and their performance. 
  - To do this I will create two new columns in the dataframe, and will call them 'total_fights' and 'win_rate'. The win rate is defined as the number of wins the fighter has, divided by the total amount of fights they have had. 
    - Here is the code: `df['total_fights']= df['wins']+df['losses']+df['draws']` and `df['win_rate'] = df['wins']/df['total_fights']`
    - The above code shows some powerful aspects of dataframes. The ability to easily create another column, as well as populate that column using element-wise addition. 


* The first interaction I want to observe is between the stance and the associated win rate(a column that we created earlier).
  - Before I do this, I want to clean the data, by dropping any na values. 
    - `df_cleaned = df.dropna(subset=['stance'])` This will clean the stance column by dropping any missing values. 
    - I also want to view how many data points there are for each stance, so we can remove any potential outliers:
        ```python
        stance_counts = df_cleaned['stance'].value_counts()
        stance_counts #Running this line in jupyter prints 
        ``` 
        ```
        stance
        Orthodox       2526
        Southpaw        560
        Switch          192
        Open Stance       7
        Sideways          3
        Name: count, dtype: int64
        ```
    - Open Stance and Sideways are not worth examining as they have so few data points compared to the other stances. Lets further clean up our data:
    ```python
    df_cleaned = df.dropna(subset=['stance'])
    df_cleaned = df[~df['stance'].isin(['Sideways', 'Open Stance'])]
    ```
    - In the previous code, I :
      - df['stance'].isin(['Sideways', 'Open Stance']) creates a boolean mask where True represents rows where the "stance" column contains either 'side' or 'open_stance'.
      - ~ negates this mask, so True becomes False and vice versa.
      - df[~df['stance'].isin(['Sideways', 'Open Stance'])] selects rows from the DataFrame where the boolean mask is True, effectively removing rows where the "stance" column contains 'Sideways' or 'Open Stance'.
    - Now I can calculate the mean win rate by stance. `mean_win_rate_by_stance = df_cleaned.groupby('stance')['win_rate'].mean().reset_index()` As you can see I used a couple different methods to create the 'mean_win_rate_by_stance' variable. One of these methods is .groupby(). This is exceedingly useful for a number of reasons: 
      1.  Aggregation: Grouping allows you to aggregate data within each group. You can compute summary statistics like mean, median, sum, count, etc., for each group, which allows us to easily gain insights to our data.
      2. Efficiency: Instead of applying operations to the entire dataset, grouping allows us to perform methods and computations on a much smaller subset. This is key when dealing with large datasets. 
      3. Flexibility: You can group by one or more columns, allowing for complex analyses by incorporating multiple criteria. This allows us to discover interactions and patterns not easily visible before. 
    - Now I can take an exploratory glance at the new variable I created. To do so, simply `print(mean_win_rate_by_stance)` which allows me to see the win rate average per stance. Doing so will give this output:
      ```
      stance  win_rate
      0    Orthodox  0.675790
      1    Southpaw  0.682777
      2     Switch   0.736506
      ```

    - Now that I have identified the interactions I want to dig into, it is time to visualize the data.


* Data Visualization
  - Unlocking the potential of data visualization offers numerous avenues, and with the aid of data frames, we can harness the power of seabornâ€”a robust tool for visualizing data. There are many options in seaborn, but the histogram stands out as a straightforward yet impactful choice, easily doable due to the integration between data frames and seaborn.
    - Before I actually create the histogram, I need to first import seaborn as sns: `import seaborn as sns`
    - Now, to create the histogram of the mean_win_rate_by_stance: 
      ```python 
      sns.barplot(x='stance', y='win_rate', data=mean_win_rate_by_stance)#I set my x axis to stance and y axis to mean_win_rate_by_stance
      plt.title('Mean Win Rate by Stance')#Creating the title
      plt.xlabel('Stance')#x axis label
      plt.ylabel('Mean Win Rate')#y axis label
      plt.show()
      ```
![Mean Win Rate by Stance]({{site.url}}/{{site.baseurl}}/assets/images/hist_2.png)
  
  - After looking at the graph, there does not seem to be that much variation among the stances. However, Switch is slightly higher, which may warrant more analysis. 


* Another effective method for identifying potentially significant relationships is by utilizing a correlation heat map. A correlation heat map proves invaluable as it visually represents the strength and direction of relationships between variables. By depicting correlations as either positive or negative, it illuminates which factors are strongly associated with one another and those that exhibit weaker or no correlation.
```python
columns_to_drop = ['name', 'nickname', 'stance', 'date_of_birth'] # Creates a variable of what columns I want to drop, name and nickname are unimportant, date_of_birth is difficult to analyze because we don't have the dates of each fight. 
df['stance_encoded'], _ = pd.factorize(df['stance'])#New column, each stance element is now a unique int, neccessary for a heat map. 
df_cleaned = df.drop(columns=columns_to_drop)
corr_matrix = df_cleaned.corr()# calculate the correlation matrix of cleaned_data. Represents pairwise correlations between all numerical columns in the data frame. 
plt.figure(figsize=(10, 8))  # Optional: Adjusts the size of the figure
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)# formating 
plt.show()
```

![Corrrelation Heat Map]({{site.url}}/{{site.baseurl}}/assets/images/heat.png)
  - The heatmap reveals some intriguing correlations that merit further investigation. However, at this point, we have reached the end of the tutorial.

# Call to Action:
  * Now that you've grasped the fundamentals of DataFrame manipulation and Data Visualization, it's time to put your skills into practice. Explore datasets aligned with your personal interests; platforms like Kaggle offer a wealth of public domain datasets for exploration. Delve into the data, uncover intriguing relationships, and visualize your findings using tools like Seaborn or other visualization libraries. Have a blast with your exploration, and don't forget to share your experience! Drop a comment letting me know your thoughts on this tutorial and any suggestions for improvement. This marks my first step into Data Science blogging, and I'm eager to hear your feedback. Hope you found the tutorial enjoyable and informative!
  ---
  ---
- Seaborn documentation can be found here; [seaborn](https://seaborn.pydata.org/)
- Pandas dataframe documentaion can be found here; [Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)





